# @package _global_

defaults:
  - /dataset@_group_.re10k: re10k_video
  - override /model/encoder: vicasplat
  - override /model/encoder/backbone: vica
  - override /loss: [mse, lpips, camera]

wandb:
  name: vicasplat_8view
  tags: [re10k, 256x256]


dataset:
  re10k:
    # overfit_to_scene: 2645536c2312c35a
    view_sampler:
      warm_up_steps: 5_000
      num_context_views: 8
      num_target_views: 12
      min_distance_between_context_views: 30
      max_distance_between_context_views: 90
      initial_min_distance_between_context_views: 5
      initial_max_distance_between_context_views: 10

model:
  encoder:
    gs_center_head_type: dpt
    gs_param_head_type: dpt_gs
    pretrained_weights: checkpoints/re10k_4view.ckpt
    backbone:
      use_intrinsic_embedding: true
      temporal_rope_theta: 30
  decoder:
    use_gsplat: false
    make_scale_invariant: false
  

train:
  distiller: ''
  distill_only_steps: 0
  distill_max_steps: 2_000
  gradient_checkpointing: false
  extended_visualization: true
  sh_warmup_every_n_steps: -1
  n_camera_opt_views: 0
  lr_cosine_annealing: true
  new_param_keywords: [gaussian_param_head, intrinsic_encoder]

optimizer:
  lr: 4e-5
  warm_up_steps: 1
  backbone_lr_multiplier: 0.25

data_loader:
  # Avoid having to spin up new processes to print out visualizations.
  train:
    re10k:
      num_workers: 4
      persistent_workers: true
      batch_size: 2
      seed: 123

  test:
    num_workers: 1
    persistent_workers: false
    batch_size: 1
    seed: 234
  val:
    re10k:
      num_workers: 1
      persistent_workers: true
      batch_size: 1
      seed: 345

trainer:
  max_steps: 20_000
  val_check_interval: 500
  # precision: bf16-mixed
  gradient_clip_val: 0.5

checkpointing:
  every_n_train_steps: 5_000
  save_weights_only: true

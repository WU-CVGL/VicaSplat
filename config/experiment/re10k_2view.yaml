# @package _global_

defaults:
  - /dataset@_group_.re10k: re10k
  - override /model/encoder: vicasplat
  - override /model/encoder/backbone: vica
  - override /loss: [mse, lpips, camera]

wandb:
  name: vicasplat_2view
  tags: [re10k, 256x256]

dataset:
  re10k:
    # overfit_to_scene: ""
    view_sampler:
      warm_up_steps: 10_000

model:
  encoder:
    gs_center_head_type: dpt
    gs_param_head_type: dpt_gs
    pretrained_weights: checkpoints/distill.ckpt
    backbone:
      use_intrinsic_embedding: true
      temporal_rope_theta: 10
  decoder:
    use_gsplat: false
    make_scale_invariant: false
  

train:
  distiller: "" #'dust3r'
  distill_only_steps: 0
  distill_max_steps: 0
  gradient_checkpointing: false
  extended_visualization: true
  sh_warmup_every_n_steps: -1
  n_camera_opt_views: 0
  new_param_keywords: [gaussian_param_head, intrinsic_encoder]
  lr_cosine_annealing: true

optimizer:
  lr: 2e-4
  warm_up_steps: 200
  backbone_lr_multiplier: 0.1

data_loader:
  # Avoid having to spin up new processes to print out visualizations.
  train:
    num_workers: 8
    persistent_workers: true
    batch_size: 16
    seed: 1234

  test:
    num_workers: 4
    persistent_workers: false
    batch_size: 1
    seed: 2345
  val:
    num_workers: 1
    persistent_workers: true
    batch_size: 1
    seed: 3456


trainer:
  max_steps: 30_000
  val_check_interval: 500
  # precision: bf16-mixed
  gradient_clip_val: 0.5

checkpointing:
  every_n_train_steps: 5_000
  save_weights_only: true
